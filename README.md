# Equality-Constrained Quadratic Programming Solver

### Aim of the Project

This repository implements and benchmarks a suite of solvers for a specific class of equality-constrained quadratic programs (QP). The goal is to analyze the trade-offs between direct, iterative, and reduced-space methods for solving large-scale optimization problems, with a practical application in portfolio optimization.

---


### Methodologies Implemented

Four distinct solver strategies based on the Karush-Kuhn-Tucker (KKT) conditions were implemented and compared:

* **Dense Direct KKT**: Constructs and solves the full `(n+K) x (n+K)` KKT system using direct LU factorization.
* **Iterative KKT (GMRES)**: Solves the sparse KKT system iteratively using the Generalized Minimal Residual method, tested with and without a simple diagonal preconditioner.
* **Schur Complement Reduction**: Eliminates the primal variable `x` and solves a smaller `K x K` system for the dual variable `Î»`, using both direct and iterative (CG) approaches.
* **Null-Space Method**: Eliminates equality constraints by projecting the problem onto the null space of the constraint matrix `A` and solving a smaller, unconstrained QP.

---

### Key Findings

* [cite_start]**Accuracy vs. Scalability**: **Dense Direct** and **Null-Space** methods are the most accurate (residuals `< 10â»Â¹âµ`) but are computationally expensive ($O(nÂ³)$) and only feasible for `n â‰¤ 2000`[cite: 186, 192].
* **Iterative Performance**: **GMRES** is memory-efficient and fast for large `n`, but its accuracy degrades as the problem size increases. [cite_start]The non-preconditioned version often outperformed the simple diagonal preconditioner[cite: 97, 186, 187].
* **Best Trade-Off**: **Schur Complement** methods offer the best balance. [cite_start]The sparse, iterative version (`Schur-sp`) is extremely fast for large `n` but less accurate, while the banded version (`Schur-band`) maintains good accuracy at a moderate cost[cite: 132, 189].

---

### Application Example: Portfolio Optimization ðŸ“ˆ

[cite_start]The notebook includes a practical finance application to solve the **long-only minimum-variance portfolio problem**[cite: 195].

* [cite_start]**Process**: Fetches S&P 100 stock data, estimates the covariance matrix `Î£`, and solves the QP: $\min w^\top \Sigma w$ subject to $1^\top w=1, w \ge 0$[cite: 199, 204].
* [cite_start]**Evaluation**: The performance of portfolios generated by the custom KKT solvers is compared against the `cvxopt` solver, showing competitive out-of-sample annual returns[cite: 265].

---

### Repository Structure
Of course. Here is the corrected repository structure section for your `README.md` file.

-----

### Repository Structure

.
â”œâ”€â”€ Numerical_Optimization_(Quadratic_Programming).ipynb   # Jupyter Notebook with all code, analysis, and plots.
â””â”€â”€ NumOptReport.pdf                                       # Detailed project report explaining the theory and results.


---

### How to Run

1.  **Install Dependencies**:
    ```bash
    pip install numpy scipy pandas matplotlib seaborn yfinance cvxopt beautifulsoup4 requests lxml
    ```
2.  **Execute the Notebook**:
    Open and run the cells in `Numerical_Optimization_(Quadratic_Programming).ipynb` to reproduce the experiments and visualizations.

